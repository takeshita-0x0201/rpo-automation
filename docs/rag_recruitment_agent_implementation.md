# RAGãƒ™ãƒ¼ã‚¹æ¡ç”¨è©•ä¾¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ã‚¬ã‚¤ãƒ‰

## 1. ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“åƒ

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```mermaid
graph TD
    subgraph "AIè©•ä¾¡ãƒ•ã‚§ãƒ¼ã‚º"
        A[æ–°è¦å€™è£œè€…ãƒ‡ãƒ¼ã‚¿<br/>ãƒ¬ã‚¸ãƒ¥ãƒ¡+æ¡ç”¨è¦ä»¶] --> B[ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†]
        B --> C[ãƒ™ã‚¯ãƒˆãƒ«åŒ–]
        C --> D[RAGæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³]
        E[(ãƒ™ã‚¯ãƒˆãƒ«DB<br/>éå»ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿)] --> D
        D --> F[é¡ä¼¼äº‹ä¾‹æŠ½å‡º<br/>Top-K]
        F --> G[LLMè©•ä¾¡ã‚¨ãƒ³ã‚¸ãƒ³]
        G --> H[AIè©•ä¾¡çµæœ<br/>ã‚¹ã‚³ã‚¢+ç†ç”±]
    end
    
    subgraph "äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚§ãƒ¼ã‚º"
        H --> I[ãƒ¬ãƒ“ãƒ¥ãƒ¼UI]
        I --> J{æ¡ç”¨è²¬ä»»è€…<br/>æœ€çµ‚åˆ¤æ–­}
        J --> K[ç¢ºå®šè©•ä¾¡]
        K --> L[ãƒ‡ãƒ¼ã‚¿æ•´å½¢]
        L --> M[ãƒ™ã‚¯ãƒˆãƒ«åŒ–]
        M --> E
    end
    
    style E fill:#e1f5fe,stroke:#01579b,stroke-width:3px
```

### ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

1. **ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: éå»ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢å¯èƒ½ãªå½¢ã§ä¿æŒ
2. **RAGã‚¨ãƒ³ã‚¸ãƒ³**: é¡ä¼¼äº‹ä¾‹ã‚’æ¤œç´¢ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ´»ç”¨
3. **è©•ä¾¡ã‚¨ãƒ³ã‚¸ãƒ³**: LLMã‚’ä½¿ç”¨ã—ãŸæ¡ç‚¹ã¨ç†ç”±ç”Ÿæˆ
4. **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—**: äººé–“ã®åˆ¤æ–­ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è“„ç©

## 2. ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

### 2.1 ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‰ã®ç”Ÿãƒ‡ãƒ¼ã‚¿æ§‹é€ 

```python
{
    "id": "eval_20250110_001",
    "timestamp": "2025-01-10T14:30:00Z",
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    "job_requirement": {
        "title": "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
        "company": "æ ªå¼ä¼šç¤¾ãƒ†ãƒƒã‚¯ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³",
        "required_skills": ["Python 5å¹´ä»¥ä¸Š", "APIé–‹ç™ºçµŒé¨“", "AWS"],
        "preferred_skills": ["Docker", "Kubernetes", "ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹"],
        "team_size": "8å",
        "description": "ECãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™º..."
    },
    
    "candidate_resume": {
        "name": "å€™è£œè€…A",
        "experience": "8å¹´",
        "current_position": "ã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
        "skills": ["Python", "Django", "FastAPI", "AWS", "Docker"],
        "work_history": "2020-ç¾åœ¨: æ ªå¼ä¼šç¤¾ã€‡ã€‡ã§APIé–‹ç™ºã‚’ãƒªãƒ¼ãƒ‰...",
        "achievements": "ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ€§èƒ½ã‚’3å€ã«æ”¹å–„..."
    },
    
    # è©•ä¾¡çµæœ
    "ai_evaluation": {
        "score": 85,
        "grade": "A",  # A, B, C, D
        "positive_reasons": [
            "å¿…é ˆã‚¹ã‚­ãƒ«ã®PythonçµŒé¨“ãŒ8å¹´ã¨è¦ä»¶ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹",
            "APIé–‹ç™ºã®å®Ÿç¸¾ãŒè±Šå¯Œã§ã€è¦ä»¶ã¨å®Œå…¨ã«åˆè‡´",
            "ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–ã®æˆåŠŸçµŒé¨“ãŒæ­“è¿è¦ä»¶ã¨ä¸€è‡´"
        ],
        "concerns": [
            "KubernetesçµŒé¨“ãŒæ˜è¨˜ã•ã‚Œã¦ã„ãªã„",
            "ãƒãƒ¼ãƒ ã‚µã‚¤ã‚ºãŒç¾è·ã§5åã€è¦ä»¶ã®8åã‚ˆã‚Šå°è¦æ¨¡"
        ]
    },
    
    # äººé–“ã«ã‚ˆã‚‹æœ€çµ‚åˆ¤æ–­
    "human_review": {
        "final_score": 88,
        "final_grade": "A",
        "reviewer": "æ¡ç”¨ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å±±ç”°",
        "comments": "æŠ€è¡“åŠ›ã¯ç”³ã—åˆ†ãªã—ã€‚ãƒãƒ¼ãƒ è¦æ¨¡ã®æ‡¸å¿µã¯é¢æ¥ã§ç¢ºèª",
        "decision": "æ¬¡é¸è€ƒã¸é€²ã‚€"
    }
}
```

### 2.2 ãƒ™ã‚¯ãƒˆãƒ«åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

```python
{
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç”¨ã®çµåˆãƒ†ã‚­ã‚¹ãƒˆ
    "text": """
    ã€æ¡ç”¨è¦ä»¶ã€‘
    è·ç¨®: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢
    å¿…é ˆ: Python 5å¹´ä»¥ä¸Šã€APIé–‹ç™ºçµŒé¨“ã€AWS
    æ­“è¿: Dockerã€Kubernetesã€ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹
    ãƒãƒ¼ãƒ : 8å
    æ¥­å‹™: ECãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™º
    
    ã€å€™è£œè€…æƒ…å ±ã€‘
    çµŒé¨“å¹´æ•°: 8å¹´
    ç¾è·: ã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢
    ã‚¹ã‚­ãƒ«: Pythonã€Djangoã€FastAPIã€AWSã€Docker
    å®Ÿç¸¾: ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ€§èƒ½ã‚’3å€ã«æ”¹å–„
    """,
    
    # ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå®Ÿéš›ã¯1536æ¬¡å…ƒãªã©ï¼‰
    "vector": [
        0.0234, -0.0156, 0.0891, -0.0423, 0.0677,
        0.0112, -0.0334, 0.0756, -0.0198, 0.0543,
        # ... 1526å€‹ã®æ•°å€¤ãŒç¶šã ...
        -0.0087, 0.0465, -0.0232, 0.0819, 0.0123
    ],
    
    # æ¤œç´¢ãƒ»å‚ç…§ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    "metadata": {
        "id": "eval_20250110_001",
        "final_grade": "A",
        "final_score": 88,
        "positive_summary": "PythonçµŒé¨“è±Šå¯Œã€APIé–‹ç™ºå®Ÿç¸¾ã€ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹çµŒé¨“",
        "concern_summary": "Kubernetesæœªç¢ºèªã€ãƒãƒ¼ãƒ è¦æ¨¡å·®",
        "decision": "æ¬¡é¸è€ƒã¸é€²ã‚€",
        "job_id": "job_tech_001",
        "candidate_id": "cand_001"
    }
}
```

## 3. å®Ÿè£…ã®è©³ç´°

### 3.1 ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®é¸å®šã¨åˆæœŸåŒ–

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
import chromadb

class RecruitmentVectorDB:
    def __init__(self):
        # Embeddingãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large"  # é«˜ç²¾åº¦ãª3072æ¬¡å…ƒ
        )
        
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.client = chromadb.PersistentClient(
            path="./recruitment_vectors"
        )
        
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã®ä½œæˆ
        self.collection = self.client.get_or_create_collection(
            name="recruitment_evaluations",
            metadata={"hnsw:space": "cosine"}  # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ä½¿ç”¨
        )
        
        # LangChainç”¨ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢
        self.vectorstore = Chroma(
            client=self.client,
            collection_name="recruitment_evaluations",
            embedding_function=self.embeddings
        )
```

### 3.2 RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…

```python
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
import json

class RAGRecruitmentAgent:
    def __init__(self, vector_db: RecruitmentVectorDB):
        self.vector_db = vector_db
        self.llm = ChatOpenAI(model="gpt-4-turbo", temperature=0.2)
        
        # æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã®å®šç¾©
        self.search_tool = Tool(
            name="search_similar_cases",
            func=self._search_similar_evaluations,
            description="éå»ã®é¡ä¼¼ã—ãŸæ¡ç”¨è©•ä¾¡äº‹ä¾‹ã‚’æ¤œç´¢ã™ã‚‹"
        )
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """ã‚ãªãŸã¯æ¡ç”¨è©•ä¾¡ã®å°‚é–€å®¶ã§ã™ã€‚
            éå»ã®è©•ä¾¡äº‹ä¾‹ã‚’å‚è€ƒã«ã—ãªãŒã‚‰ã€å€™è£œè€…ã¨æ¡ç”¨è¦ä»¶ã®ãƒãƒƒãƒãƒ³ã‚°åº¦ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
            
            è©•ä¾¡ã¯ä»¥ä¸‹ã®è¦³ç‚¹ã§è¡Œã£ã¦ãã ã•ã„ï¼š
            1. å¿…é ˆã‚¹ã‚­ãƒ«ã®å……è¶³åº¦
            2. æ­“è¿ã‚¹ã‚­ãƒ«ã®ä¿æœ‰çŠ¶æ³
            3. çµŒé¨“å¹´æ•°ã¨ãƒ¬ãƒ™ãƒ«æ„Ÿ
            4. ãƒãƒ¼ãƒ è¦æ¨¡ã‚„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµŒé¨“ã®é©åˆæ€§
            5. æˆé•·ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«
            
            å¿…ãš0-100ã®ã‚¹ã‚³ã‚¢ã¨A-Dã®ã‚°ãƒ¬ãƒ¼ãƒ‰ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"""),
            
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
        agent = create_openai_tools_agent(
            llm=self.llm,
            tools=[self.search_tool],
            prompt=self.prompt
        )
        
        self.agent_executor = AgentExecutor(
            agent=agent,
            tools=[self.search_tool],
            verbose=True,
            max_iterations=4  # æœ€å¤§4å›ã®æ¤œç´¢
        )
    
    def _search_similar_evaluations(self, query: str) -> str:
        """é¡ä¼¼ã™ã‚‹éå»ã®è©•ä¾¡äº‹ä¾‹ã‚’æ¤œç´¢"""
        results = self.vector_db.vectorstore.similarity_search_with_score(
            query=query,
            k=3  # Top-3ã‚’å–å¾—
        )
        
        similar_cases = []
        for doc, score in results:
            case = {
                "similarity_score": round(1 - score, 3),  # é¡ä¼¼åº¦
                "grade": doc.metadata.get("final_grade"),
                "score": doc.metadata.get("final_score"),
                "positive": doc.metadata.get("positive_summary"),
                "concerns": doc.metadata.get("concern_summary"),
                "decision": doc.metadata.get("decision")
            }
            similar_cases.append(case)
        
        return json.dumps(similar_cases, ensure_ascii=False, indent=2)
    
    def evaluate_candidate(self, job_requirement: dict, candidate_resume: dict) -> dict:
        """å€™è£œè€…ã‚’è©•ä¾¡"""
        # è©•ä¾¡ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        input_text = self._format_evaluation_input(job_requirement, candidate_resume)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
        result = self.agent_executor.invoke({
            "input": input_text
        })
        
        # çµæœã‚’ãƒ‘ãƒ¼ã‚¹
        return self._parse_evaluation_result(result["output"])
```

### 3.3 äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–ã‚Šè¾¼ã‚€ä»•çµ„ã¿

```python
class FeedbackLoop:
    def __init__(self, vector_db: RecruitmentVectorDB):
        self.vector_db = vector_db
    
    def add_human_reviewed_data(self, evaluation_data: dict):
        """äººé–“ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ """
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
        text = self._create_searchable_text(
            evaluation_data["job_requirement"],
            evaluation_data["candidate_resume"]
        )
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        metadata = {
            "id": evaluation_data["id"],
            "final_grade": evaluation_data["human_review"]["final_grade"],
            "final_score": evaluation_data["human_review"]["final_score"],
            "positive_summary": self._summarize_reasons(
                evaluation_data["ai_evaluation"]["positive_reasons"]
            ),
            "concern_summary": self._summarize_reasons(
                evaluation_data["ai_evaluation"]["concerns"]
            ),
            "decision": evaluation_data["human_review"]["decision"],
            "job_id": evaluation_data["job_requirement"].get("id"),
            "candidate_id": evaluation_data["candidate_resume"].get("id"),
            "reviewer": evaluation_data["human_review"]["reviewer"],
            "timestamp": evaluation_data["timestamp"]
        }
        
        # ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ 
        self.vector_db.vectorstore.add_texts(
            texts=[text],
            metadatas=[metadata],
            ids=[evaluation_data["id"]]
        )
        
        print(f"âœ… è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ {evaluation_data['id']} ã‚’ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ ã—ã¾ã—ãŸ")
    
    def _create_searchable_text(self, job_req: dict, resume: dict) -> str:
        """æ¤œç´¢ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        return f"""
        ã€æ¡ç”¨è¦ä»¶ã€‘
        è·ç¨®: {job_req.get('title')}
        å¿…é ˆ: {', '.join(job_req.get('required_skills', []))}
        æ­“è¿: {', '.join(job_req.get('preferred_skills', []))}
        ãƒãƒ¼ãƒ : {job_req.get('team_size')}
        æ¥­å‹™: {job_req.get('description', '')[:200]}
        
        ã€å€™è£œè€…æƒ…å ±ã€‘
        çµŒé¨“å¹´æ•°: {resume.get('experience')}
        ç¾è·: {resume.get('current_position')}
        ã‚¹ã‚­ãƒ«: {', '.join(resume.get('skills', []))}
        å®Ÿç¸¾: {resume.get('achievements', '')[:200]}
        """
```

### 3.4 ãƒ¬ãƒ“ãƒ¥ãƒ¼UIï¼ˆStreamlitå®Ÿè£…ä¾‹ï¼‰

```python
import streamlit as st
from datetime import datetime

class ReviewUI:
    def __init__(self, agent: RAGRecruitmentAgent, feedback_loop: FeedbackLoop):
        self.agent = agent
        self.feedback_loop = feedback_loop
    
    def run(self):
        st.title("ğŸ¯ æ¡ç”¨å€™è£œè€…AIè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›
        with st.sidebar:
            st.header("æ¡ç”¨è¦ä»¶")
            job_title = st.text_input("è·ç¨®å")
            required_skills = st.text_area("å¿…é ˆã‚¹ã‚­ãƒ«ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰")
            preferred_skills = st.text_area("æ­“è¿ã‚¹ã‚­ãƒ«ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰")
            team_size = st.text_input("ãƒãƒ¼ãƒ è¦æ¨¡")
            
            st.header("å€™è£œè€…æƒ…å ±")
            experience = st.text_input("çµŒé¨“å¹´æ•°")
            current_position = st.text_input("ç¾åœ¨ã®å½¹è·")
            skills = st.text_area("ä¿æœ‰ã‚¹ã‚­ãƒ«ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰")
            achievements = st.text_area("ä¸»ãªå®Ÿç¸¾")
            
            if st.button("ğŸ¤– AIè©•ä¾¡ã‚’å®Ÿè¡Œ"):
                # AIè©•ä¾¡ã‚’å®Ÿè¡Œ
                self._run_evaluation(...)
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã§çµæœè¡¨ç¤º
        if "ai_result" in st.session_state:
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ¤– AIè©•ä¾¡çµæœ")
                st.metric("ã‚¹ã‚³ã‚¢", st.session_state.ai_result["score"])
                st.metric("ã‚°ãƒ¬ãƒ¼ãƒ‰", st.session_state.ai_result["grade"])
                st.write("**ãƒã‚¸ãƒ†ã‚£ãƒ–ãªç‚¹:**")
                for reason in st.session_state.ai_result["positive_reasons"]:
                    st.write(f"âœ… {reason}")
                
            with col2:
                st.subheader("ğŸ‘¤ æœ€çµ‚è©•ä¾¡ï¼ˆäººé–“ï¼‰")
                final_score = st.slider("æœ€çµ‚ã‚¹ã‚³ã‚¢", 0, 100, 
                                      st.session_state.ai_result["score"])
                final_grade = st.selectbox("æœ€çµ‚ã‚°ãƒ¬ãƒ¼ãƒ‰", ["A", "B", "C", "D"])
                comments = st.text_area("ã‚³ãƒ¡ãƒ³ãƒˆ")
                decision = st.selectbox("åˆ¤å®š", 
                                      ["æ¬¡é¸è€ƒã¸é€²ã‚€", "ä¿ç•™", "ä¸æ¡ç”¨"])
                
                if st.button("âœ… è©•ä¾¡ã‚’ç¢ºå®š"):
                    self._save_final_evaluation(...)
```

## 4. å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ

### 4.1 ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®æœ€é©åŒ–

1. **é©åˆ‡ãªEmbeddingãƒ¢ãƒ‡ãƒ«ã®é¸æŠ**
   - æ—¥æœ¬èªå¯¾å¿œ: `multilingual-e5-large`
   - é«˜ç²¾åº¦: `text-embedding-3-large`
   - ã‚³ã‚¹ãƒˆé‡è¦–: `text-embedding-3-small`

2. **ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†**
   - è¦ä»¶ã¨ãƒ¬ã‚¸ãƒ¥ãƒ¡ã®æ§‹é€ åŒ–
   - é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å¼·èª¿
   - ãƒã‚¤ã‚ºã®é™¤å»

### 4.2 æ¤œç´¢ç²¾åº¦ã®å‘ä¸Š

1. **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢**
   ```python
   # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®çµ„ã¿åˆã‚ã›
   def hybrid_search(self, query, keyword_filters=None):
       vector_results = self.vector_search(query)
       if keyword_filters:
           filtered = [r for r in vector_results 
                      if all(kw in r.text for kw in keyword_filters)]
           return filtered
       return vector_results
   ```

2. **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**
   ```python
   # åŒã˜ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚„è·ç¨®ã®äº‹ä¾‹ã‚’å„ªå…ˆ
   results = vectorstore.similarity_search(
       query,
       filter={"job_category": "backend_engineer"}
   )
   ```

### 4.3 ç¶™ç¶šçš„ãªæ”¹å–„

1. **å®šæœŸçš„ãªå†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹**
   - æ–°ã—ã„Embeddingãƒ¢ãƒ‡ãƒ«ã¸ã®ç§»è¡Œ
   - ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†ã®æ”¹å–„

2. **è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½è·¡**
   - AIã¨äººé–“ã®è©•ä¾¡ã®ä¹–é›¢åº¦
   - æ¡ç”¨æˆåŠŸç‡ã¨ã®ç›¸é–¢

## 5. ã¾ã¨ã‚

ã“ã®RAGãƒ™ãƒ¼ã‚¹ã®ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šï¼š

1. **åˆæœŸæ®µéš**: éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã—ã¦AIãŒè©•ä¾¡
2. **æˆé•·æ®µéš**: äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§ç¶™ç¶šçš„ã«æ”¹å–„
3. **æˆç†Ÿæ®µéš**: ä¼æ¥­ç‹¬è‡ªã®æ¡ç”¨åŸºæº–ã‚’å®Œå…¨ã«ç†è§£ã—ãŸAI

ã¨ã„ã†é€²åŒ–ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚